{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142b2bf6",
   "metadata": {},
   "source": [
    "# Methods of Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0daac8",
   "metadata": {},
   "source": [
    "Three approaches of dealing with missing values;\n",
    "1. Drop Columns with Missing Values\n",
    "2. Imputation\n",
    "3. An Extension to Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d8bb7",
   "metadata": {},
   "source": [
    "Missing numbers are represented as NaN (Not a Number). To check which cells have missing values:\n",
    "\n",
    "- Total missing values for each feature\n",
    "     \n",
    "     df.isnull().sum()\n",
    "    \n",
    "    \n",
    "- Any missing values\n",
    "     \n",
    "     df.isnull().values.any()\n",
    "    \n",
    "    \n",
    "- Total number of missing values\n",
    "     \n",
    "     df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6e919",
   "metadata": {},
   "source": [
    "### 1. Drop Columns with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993dee3a",
   "metadata": {},
   "source": [
    "For DataFrame 'df', you can drop columns with missing values. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd31d946",
   "metadata": {},
   "source": [
    "df_without_missing_values = df.dropna(axis=1)\n",
    "\n",
    "OR\n",
    "\n",
    "df_without_missing_values = df.drop(\"xyz\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc27164",
   "metadata": {},
   "source": [
    "In a case where there are both training dataset and a test dataset and you want to drop the same columns in both DataFrames."
   ]
  },
  {
   "cell_type": "raw",
   "id": "499e988e",
   "metadata": {},
   "source": [
    "cols_with_missing = [col for col in df_train.columns \n",
    "                                 if df_train[col].isnull().any()]\n",
    "                                 \n",
    "reduced_df_train = df_train.drop(cols_with_missing, axis=1)\n",
    "\n",
    "reduced_df_test = df_test.drop(cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c37a85",
   "metadata": {},
   "source": [
    "If those columns had useful information (in the places that were not missing), your model loses access to this information when the column is dropped. Also, if your test data has missing values in places where your training data did not, this will result in an error.\n",
    "\n",
    "So, it's somewhat usually not the best solution. However, it can be useful when most values in a column are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5a70b",
   "metadata": {},
   "source": [
    "### 2. Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfe792",
   "metadata": {},
   "source": [
    "Imputation fills in the missing value with some number. The imputed value won't be exactly right in most cases, but it usually gives more accurate models than dropping the column entirely.\n",
    "\n",
    "This is done with;"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f68095e8",
   "metadata": {},
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer()\n",
    "data_with_imputed_values = my_imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c3bd5",
   "metadata": {},
   "source": [
    "The default behavior fills in the mean value for imputation. Statisticians have researched more complex strategies, but those complex strategies typically give no benefit once you plug the results into sophisticated machine learning models.\n",
    "\n",
    "One (of many) nice things about Imputation is that it can be included in a scikit-learn Pipeline. Pipelines simplify model building, model validation and model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcc0a0",
   "metadata": {},
   "source": [
    "### 3. An Extension with Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc04db",
   "metadata": {},
   "source": [
    "Imputation is the standard approach, and it usually works well. However, imputed values may by systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing. Here's how it might look:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f37f85c",
   "metadata": {},
   "source": [
    "# make copy to avoid changing original data (when Imputing)\n",
    "new_data = df.copy()\n",
    "\n",
    "# make new columns indicating what will be imputed\n",
    "cols_with_missing = (col for col in new_data.columns \n",
    "                                 if new_data[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    new_data[col + '_was_missing'] = new_data[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "new_data = pd.DataFrame(my_imputer.fit_transform(new_data))\n",
    "new_data.columns = df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a2e93",
   "metadata": {},
   "source": [
    "In some cases this approach will meaningfully improve results. In other cases, it doesn't help at all."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
